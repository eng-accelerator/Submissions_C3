{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48078012864641a6806e769d0e02d084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_625677a2dc3d49d99c360de95136ba82",
              "IPY_MODEL_39ad3178176044ad86af26aa0c854fcb",
              "IPY_MODEL_8f94a21d38de40afb3e856261e4379a8"
            ],
            "layout": "IPY_MODEL_e815887fd5784d77bace449a1073802d"
          }
        },
        "625677a2dc3d49d99c360de95136ba82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affde5adc9d5445aaa3f40b239007532",
            "placeholder": "​",
            "style": "IPY_MODEL_76a2be4f598b4a0ab92adccc516c9801",
            "value": "Parsing nodes: 100%"
          }
        },
        "39ad3178176044ad86af26aa0c854fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf985339ada483e8a5d3f8dd0120494",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b618260c16ad4413b5050c5dfb439d58",
            "value": 42
          }
        },
        "8f94a21d38de40afb3e856261e4379a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6265e54537c406ea7646e4fade37a54",
            "placeholder": "​",
            "style": "IPY_MODEL_d760291f72644be695b95af87c00507b",
            "value": " 42/42 [00:02&lt;00:00, 21.04it/s]"
          }
        },
        "e815887fd5784d77bace449a1073802d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affde5adc9d5445aaa3f40b239007532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a2be4f598b4a0ab92adccc516c9801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf985339ada483e8a5d3f8dd0120494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b618260c16ad4413b5050c5dfb439d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6265e54537c406ea7646e4fade37a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d760291f72644be695b95af87c00507b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a80740e173a9458caee3adf94aa6fe08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9372852724a4664b2e56a51d7c01f42",
              "IPY_MODEL_89893e0317ec4eb1af89a1b6cb2aca04",
              "IPY_MODEL_95da3829512c4126b1d23d667128e401"
            ],
            "layout": "IPY_MODEL_f6cf685ccfdc4ef68de99e1c85dc4835"
          }
        },
        "e9372852724a4664b2e56a51d7c01f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4a2c604b6e406598becd550ae2c30b",
            "placeholder": "​",
            "style": "IPY_MODEL_be9f838c40ea47d8b58d68085a924bf7",
            "value": "Generating embeddings: 100%"
          }
        },
        "89893e0317ec4eb1af89a1b6cb2aca04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47825e3ba8bf44b2beec10189b7c61fe",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df0f608f7410411ca1d4a4b348df076a",
            "value": 90
          }
        },
        "95da3829512c4126b1d23d667128e401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0df2fc2046224fdaa59f05d224a66bf3",
            "placeholder": "​",
            "style": "IPY_MODEL_6cfcac6becbb4f0c90b8b346b67e8cfd",
            "value": " 90/90 [01:04&lt;00:00,  1.47it/s]"
          }
        },
        "f6cf685ccfdc4ef68de99e1c85dc4835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4a2c604b6e406598becd550ae2c30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9f838c40ea47d8b58d68085a924bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47825e3ba8bf44b2beec10189b7c61fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0f608f7410411ca1d4a4b348df076a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0df2fc2046224fdaa59f05d224a66bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfcac6becbb4f0c90b8b346b67e8cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r '/content/drive/MyDrive/session_2/requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ZVbgjMzs7M64",
        "outputId": "87e4ac14-9185-4ac2-f138-a79fe5a5c540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 1)) (4.13.5)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 3)) (2.187.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 4)) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (5.50.0)\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 7)) (1.14.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (7.34.0)\n",
            "Collecting lancedb (from -r /content/drive/MyDrive/session_2/requirements.txt (line 11))\n",
            "  Downloading lancedb-0.25.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index-0.14.10-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-vector-stores-lancedb (from -r /content/drive/MyDrive/session_2/requirements.txt (line 13))\n",
            "  Downloading llama_index_vector_stores_lancedb-0.4.2-py3-none-any.whl.metadata (460 bytes)\n",
            "Collecting llama-index-embeddings-huggingface (from -r /content/drive/MyDrive/session_2/requirements.txt (line 14))\n",
            "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
            "Collecting llama-index-llms-huggingface-api (from -r /content/drive/MyDrive/session_2/requirements.txt (line 15))\n",
            "  Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-embeddings-openai (from -r /content/drive/MyDrive/session_2/requirements.txt (line 16))\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-llms-openrouter (from -r /content/drive/MyDrive/session_2/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 18)) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 19)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 21)) (2.8.1)\n",
            "Collecting openai-whisper (from -r /content/drive/MyDrive/session_2/requirements.txt (line 22))\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 23)) (2.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (5.1.2)\n",
            "Collecting yt-dlp (from -r /content/drive/MyDrive/session_2/requirements.txt (line 25))\n",
            "  Downloading yt_dlp-2025.12.8-py3-none-any.whl.metadata (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (3.8.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/session_2/requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/session_2/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/session_2/requirements.txt (line 3)) (0.31.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/session_2/requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/session_2/requirements.txt (line 4)) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/session_2/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/session_2/requirements.txt (line 4)) (4.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/session_2/requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/session_2/requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/session_2/requirements.txt (line 8)) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/session_2/requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/session_2/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (4.9.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 11)) (18.1.0)\n",
            "Collecting lance-namespace>=0.0.16 (from lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 11))\n",
            "  Downloading lance_namespace-0.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.10 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_core-0.14.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_llms_openai-0.6.10-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pylance (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 13))\n",
            "  Downloading pylance-0.39.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tantivy (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 13))\n",
            "  Downloading tantivy-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (336 bytes)\n",
            "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama-index-llms-openrouter->-r /content/drive/MyDrive/session_2/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/session_2/requirements.txt (line 18)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/session_2/requirements.txt (line 18)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/session_2/requirements.txt (line 18)) (2025.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/session_2/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/session_2/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/session_2/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/session_2/requirements.txt (line 21)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/session_2/requirements.txt (line 21)) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/session_2/requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (2.9.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/session_2/requirements.txt (line 23)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/session_2/requirements.txt (line 23)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/session_2/requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (4.57.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (1.16.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (0.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->-r /content/drive/MyDrive/session_2/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (3.13.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/session_2/requirements.txt (line 9)) (5.9.1)\n",
            "Collecting lance-namespace-urllib3-client (from lance-namespace>=0.0.16->lancedb->-r /content/drive/MyDrive/session_2/requirements.txt (line 11))\n",
            "  Downloading lance_namespace_urllib3_client-0.2.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (0.21.0)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_workflows-2.11.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (4.5.0)\n",
            "Collecting setuptools>=18.5 (from ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10))\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (9.1.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (2.0.1)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (0.7.1)\n",
            "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading pypdf-6.4.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/session_2/requirements.txt (line 10)) (0.2.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->-r /content/drive/MyDrive/session_2/requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/session_2/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/session_2/requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (1.14.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (1.11.1.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (0.7.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r /content/drive/MyDrive/session_2/requirements.txt (line 26)) (7.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/session_2/requirements.txt (line 24)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/session_2/requirements.txt (line 14)) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->-r /content/drive/MyDrive/session_2/requirements.txt (line 22)) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12)) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/session_2/requirements.txt (line 6)) (0.1.2)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index->-r /content/drive/MyDrive/session_2/requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading lancedb-0.25.3-cp39-abi3-manylinux_2_28_x86_64.whl (39.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.2/39.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.14.10-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_vector_stores_lancedb-0.4.2-py3-none-any.whl (7.9 kB)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl (4.5 kB)\n",
            "Downloading yt_dlp-2025.12.8-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lance_namespace-0.2.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.10-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.10-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl (4.7 kB)\n",
            "Downloading llama_index_readers_file-0.5.5-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading pylance-0.39.0-cp39-abi3-manylinux_2_28_x86_64.whl (48.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tantivy-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.11.5-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.4.1-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading lance_namespace_urllib3_client-0.2.1-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.5/228.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=9da8a8220967cbb84994b66792aef1ecfcffb74696b04cc76ce6ed601f73aac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, yt-dlp, wrapt, tantivy, setuptools, pypdf, mypy-extensions, marshmallow, jedi, colorama, typing-inspect, griffe, deprecated, llama-index-instrumentation, llama-cloud, lance-namespace-urllib3-client, dataclasses-json, banks, openai-whisper, llama-index-workflows, lance-namespace, pylance, llama-index-core, lancedb, llama-index-vector-stores-lancedb, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface-api, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-openrouter, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "Successfully installed banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.15.0 jedi-0.19.2 lance-namespace-0.2.1 lance-namespace-urllib3-client-0.2.1 lancedb-0.25.3 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.10 llama-index-cli-0.5.3 llama-index-core-0.14.10 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-api-0.6.1 llama-index-llms-openai-0.6.10 llama-index-llms-openai-like-0.5.3 llama-index-llms-openrouter-0.4.2 llama-index-readers-file-0.5.5 llama-index-readers-llama-parse-0.5.1 llama-index-vector-stores-lancedb-0.4.2 llama-index-workflows-2.11.5 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 openai-whisper-20250625 pylance-0.39.0 pypdf-6.4.1 setuptools-80.9.0 striprtf-0.0.26 tantivy-0.25.1 typing-inspect-0.9.0 wrapt-1.17.3 yt-dlp-2025.12.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "49f50038babf401993fd0193eb33e2d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries for advanced RAG\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "print(\"✅ Advanced RAG libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7D7Ayhm7mLQ",
        "outputId": "a4a8b960-439e-4dd0-91e1-f88c4986967d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Advanced RAG libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "# For accessing Colab secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"✅ Advanced RAG libraries imported successfully!\")\n",
        "\n",
        "# Configure Advanced RAG Settings (Using OpenRouter)\n",
        "def setup_advanced_rag_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
        "    Uses local embeddings and OpenRouter for LLM operations.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key\n",
        "    api_key = userdata.get(\"OPENROUTER_API_KEY\") # Use userdata.get() for Colab secrets\n",
        "    if not api_key:\n",
        "        print(\"⚠️  OPENROUTER_API_KEY not found - LLM operations will be limited\")\n",
        "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
        "    else:\n",
        "        print(\"✅ OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
        "\n",
        "        # Configure OpenRouter LLM\n",
        "        Settings.llm = OpenRouter(\n",
        "            api_key=api_key,\n",
        "            model=\"gpt-4o\",\n",
        "            temperature=0.1  # Lower temperature for more consistent responses\n",
        "        )\n",
        "\n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # Advanced RAG configuration\n",
        "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
        "    Settings.chunk_overlap = 50\n",
        "\n",
        "    print(\"✅ Advanced RAG settings configured\")\n",
        "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
        "    print(\"   - Using local embeddings for cost efficiency\")\n",
        "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_advanced_rag_settings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSdPQnM67sWx",
        "outputId": "ae78d092-3cf9-41b6-9bb1-15ddfbb2dc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Advanced RAG libraries imported successfully!\n",
            "✅ OPENROUTER_API_KEY found - full advanced RAG functionality available\n",
            "✅ Advanced RAG settings configured\n",
            "   - Chunk size: 512 (optimized for precision)\n",
            "   - Using local embeddings for cost efficiency\n",
            "   - OpenRouter LLM ready for response synthesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
        "def setup_basic_index(data_folder: str = \"/content/drive/MyDrive/session_2/data\", force_rebuild: bool = False):\n",
        "    \"\"\"\n",
        "    Create a basic vector index that we'll enhance with advanced techniques.\n",
        "    This reuses the concepts from Assignment 1.\n",
        "    \"\"\"\n",
        "    # Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "        uri=\"./advanced_rag_vectordb\",\n",
        "        table_name=\"documents\"\n",
        "    )\n",
        "\n",
        "    # Load documents\n",
        "    if not Path(data_folder).exists():\n",
        "        print(f\"❌ Data folder not found: {data_folder}\")\n",
        "        return None\n",
        "\n",
        "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "    documents = reader.load_data()\n",
        "\n",
        "    # Create storage context and index\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents,\n",
        "        storage_context=storage_context,\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Basic index created with {len(documents)} documents\")\n",
        "    print(\"   Ready for advanced RAG techniques!\")\n",
        "    return index\n",
        "\n",
        "# Create the basic index\n",
        "print(\"📁 Setting up basic index for advanced RAG...\")\n",
        "index = setup_basic_index()\n",
        "\n",
        "if index:\n",
        "    print(\"🚀 Ready to implement advanced RAG techniques!\")\n",
        "else:\n",
        "    print(\"❌ Failed to create index - check data folder path\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "48078012864641a6806e769d0e02d084",
            "625677a2dc3d49d99c360de95136ba82",
            "39ad3178176044ad86af26aa0c854fcb",
            "8f94a21d38de40afb3e856261e4379a8",
            "e815887fd5784d77bace449a1073802d",
            "affde5adc9d5445aaa3f40b239007532",
            "76a2be4f598b4a0ab92adccc516c9801",
            "fdf985339ada483e8a5d3f8dd0120494",
            "b618260c16ad4413b5050c5dfb439d58",
            "e6265e54537c406ea7646e4fade37a54",
            "d760291f72644be695b95af87c00507b",
            "a80740e173a9458caee3adf94aa6fe08",
            "e9372852724a4664b2e56a51d7c01f42",
            "89893e0317ec4eb1af89a1b6cb2aca04",
            "95da3829512c4126b1d23d667128e401",
            "f6cf685ccfdc4ef68de99e1c85dc4835",
            "8b4a2c604b6e406598becd550ae2c30b",
            "be9f838c40ea47d8b58d68085a924bf7",
            "47825e3ba8bf44b2beec10189b7c61fe",
            "df0f608f7410411ca1d4a4b348df076a",
            "0df2fc2046224fdaa59f05d224a66bf3",
            "6cfcac6becbb4f0c90b8b346b67e8cfd"
          ]
        },
        "id": "NS5j0ctR8Qug",
        "outputId": "3cbc9603-bbfc-4bad-85af-4cb45bb86b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.vector_stores.lancedb.base:Table documents doesn't exist yet. Please add some data to create it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Setting up basic index for advanced RAG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 39.5MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/42 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48078012864641a6806e769d0e02d084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a80740e173a9458caee3adf94aa6fe08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Basic index created with 42 documents\n",
            "   Ready for advanced RAG techniques!\n",
            "🚀 Ready to implement advanced RAG techniques!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a query engine that filters results based on similarity scores.\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
        "        top_k: Number of initial results to retrieve before filtering\n",
        "\n",
        "    Returns:\n",
        "        Query engine with similarity filtering\n",
        "    \"\"\"\n",
        "    # Create similarity postprocessor with the cutoff threshold\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # Create query engine with similarity filtering\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor]\n",
        "    )\n",
        "\n",
        "    return query_engine\n",
        "\n",
        "# Testing the function (moved outside the function definition)\n",
        "if index:\n",
        "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
        "\n",
        "    if filtered_engine:\n",
        "        print(\"✅ Query engine with similarity filtering created\")\n",
        "\n",
        "        # Test query\n",
        "        test_query = \"What are the benefits of AI agents?\"\n",
        "        print(f\"\\n🔍 Testing query: '{test_query}'\")\n",
        "\n",
        "        response = filtered_engine.query(test_query)\n",
        "        print(f\"📝 Response: {response}\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create filtered query engine\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OITbiS_C8sJo",
        "outputId": "a43a00a3-bf48-4d5b-c3a4-c56812af3a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Query engine with similarity filtering created\n",
            "\n",
            "🔍 Testing query: 'What are the benefits of AI agents?'\n",
            "📝 Response: AI agents offer several benefits, including the enhancement of language model capabilities to solve real-world problems with robust problem-solving skills. They can operate in complex environments, make autonomous decisions, and assist humans in various tasks. AI agents are proficient in reasoning and planning, allowing them to swiftly learn new tasks and make informed decisions even in uncertain conditions. They can also employ multiple tools to address complex issues, interact with external data sources, and access information from APIs. Additionally, multi-agent architectures can improve performance by enabling parallel task execution and collaboration among agents, especially when multiple distinct execution paths are required.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response_synthesizers import TreeSummarize\n",
        "\n",
        "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        top_k: Number of results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Query engine with TreeSummarize synthesis\n",
        "    \"\"\"\n",
        "    # Create TreeSummarize response synthesizer\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    # Create query engine with the synthesizer\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        response_synthesizer=tree_synthesizer,\n",
        "    )\n",
        "\n",
        "    return query_engine\n",
        "# Test the function\n",
        "if index:\n",
        "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
        "\n",
        "    if tree_engine:\n",
        "        print(\"✅ Query engine with TreeSummarize created\")\n",
        "\n",
        "        # Test with a complex analytical query\n",
        "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
        "        print(f\"\\n🔍 Testing analytical query: '{analytical_query}'\")\n",
        "\n",
        "        # Now this will work:\n",
        "        # response = tree_engine.query(analytical_query)\n",
        "        # print(f\"📝 TreeSummarize Response:\\n{response}\")\n",
        "        print(\"   (Uncomment the query lines above to see the full synthesized answer)\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create TreeSummarize query engine\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDfNykp-9SCe",
        "outputId": "b6f106a2-6f37-4971-b93d-d6f286c5493e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Query engine with TreeSummarize created\n",
            "\n",
            "🔍 Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n",
            "   (Uncomment the query lines above to see the full synthesized answer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from pydantic import BaseModel, Field # Ensure BaseModel is imported\n",
        "from typing import List\n",
        "\n",
        "# Define the Pydantic model for structured output\n",
        "class ResearchPaperInfo(BaseModel):\n",
        "    title: str = Field(description=\"Main title or concept name\")\n",
        "    key_points: List[str] = Field(description=\"3-5 key points or findings\")\n",
        "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
        "    summary: str = Field(description=\"2-3 sentence concise summary\")\n",
        "\n",
        "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
        "    \"\"\"\n",
        "    Create a structured output program using Pydantic models.\n",
        "\n",
        "    Args:\n",
        "        output_model: Pydantic model class for structured output\n",
        "\n",
        "    Returns:\n",
        "        LLMTextCompletionProgram that returns structured data\n",
        "    \"\"\"\n",
        "    # Create output parser with the Pydantic model\n",
        "    output_parser = PydanticOutputParser(output_cls=output_model)\n",
        "\n",
        "    # Create the structured output program\n",
        "    program = LLMTextCompletionProgram.from_defaults(\n",
        "        output_parser=output_parser,\n",
        "        prompt_template_str=(\n",
        "            \"You are an AI assistant that extracts structured information about \"\n",
        "            \"AI research papers or AI concepts.\\n\\n\"\n",
        "            \"Use the following CONTEXT to answer the QUERY and fill in these fields:\\n\"\n",
        "            \"- title: main title or concept name\\n\"\n",
        "            \"- key_points: 3-5 key points or findings\\n\"\n",
        "            \"- applications: practical applications or use cases\\n\"\n",
        "            \"- summary: 2-3 sentence concise summary\\n\\n\"\n",
        "            \"CONTEXT:\\n{context}\\n\\n\"\n",
        "            \"QUERY:\\n{query}\\n\\n\"\n",
        "            \"Return ONLY a JSON object that matches the required structure.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return program\n",
        "\n",
        "# Initialize the structured program\n",
        "structured_program = create_structured_output_program()\n",
        "\n",
        "# Define example context and query for testing\n",
        "context = (\n",
        "    \"AI agents are designed to autonomously perform tasks in complex environments. \"\n",
        "    \"They leverage advanced reasoning and planning capabilities, often using multiple tools \"\n",
        "    \"and interacting with external data sources and APIs. \"\n",
        "    \"Benefits include enhanced problem-solving, autonomous decision-making, and assistance in human tasks. \"\n",
        "    \"Multi-agent architectures can further improve performance through parallel task execution and collaboration.\"\n",
        ")\n",
        "structure_query = \"Extract key information about AI Agents.\"\n",
        "\n",
        "response = structured_program(context=context, query=structure_query)\n",
        "print(\"📊 Structured Response:\", response)\n",
        "print(\"Title:\", response.title)\n",
        "print(\"Key points:\", response.key_points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REfD6X8R9kF8",
        "outputId": "f096d760-3289-4ecd-bb9f-ec219335ed3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Structured Response: title='AI Agents' key_points=['AI agents autonomously perform tasks in complex environments.', 'They utilize advanced reasoning and planning capabilities.', 'AI agents can interact with external data sources and APIs.', 'Multi-agent architectures enable parallel task execution and collaboration.', 'They enhance problem-solving and autonomous decision-making.'] applications=['Autonomous decision-making in dynamic environments', 'Enhanced problem-solving in complex tasks', 'Assistance in human tasks through automation', 'Collaboration in multi-agent systems for improved performance'] summary='AI agents are designed to autonomously perform tasks in complex environments by leveraging advanced reasoning and planning capabilities. They can interact with external data sources and APIs, and multi-agent architectures allow for parallel task execution and collaboration, enhancing problem-solving and decision-making.'\n",
            "Title: AI Agents\n",
            "Key points: ['AI agents autonomously perform tasks in complex environments.', 'They utilize advanced reasoning and planning capabilities.', 'AI agents can interact with external data sources and APIs.', 'Multi-agent architectures enable parallel task execution and collaboration.', 'They enhance problem-solving and autonomous decision-making.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize\n",
        "\n",
        "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score for filtering\n",
        "        top_k: Number of initial results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Advanced query engine with filtering and synthesis combined\n",
        "    \"\"\"\n",
        "    # Create similarity postprocessor\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # Create TreeSummarize for comprehensive responses\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    # Create the comprehensive query engine combining both techniques\n",
        "    advanced_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor],\n",
        "        response_synthesizer=tree_synthesizer,\n",
        "    )\n",
        "\n",
        "    return advanced_engine\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    advanced_pipeline = create_advanced_rag_pipeline(index, similarity_cutoff=0.3)\n",
        "\n",
        "    if advanced_pipeline:\n",
        "        print(\"✅ Advanced RAG pipeline created\")\n",
        "\n",
        "        # Define a complex query for testing\n",
        "        complex_query = \"What are the key differences between various types of AI agents described in the documents?\"\n",
        "        print(f\"\\n🔍 Testing complex query: '{complex_query}'\")\n",
        "\n",
        "        response = advanced_pipeline.query(complex_query)\n",
        "        print(f\"🚀 Advanced RAG Response:\\n{response}\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create advanced RAG pipeline\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOjfvqqW-3SQ",
        "outputId": "e0dacbaa-b780-4c8f-c93b-76819e03fdd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Advanced RAG pipeline created\n",
            "\n",
            "🔍 Testing complex query: 'What are the key differences between various types of AI agents described in the documents?'\n",
            "🚀 Advanced RAG Response:\n",
            "The key differences between the various types of AI agents are based on their design and functionality:\n",
            "\n",
            "1. **Autonomous Agents**: These agents are designed for independent task execution, handling complex tasks without external input. They are characterized by high complexity and a steep learning curve, making them suitable for tasks that require autonomy.\n",
            "\n",
            "2. **Tool-Using Agents**: These agents are equipped to interact with external tools and data sources, which enhances their capabilities in tasks like document understanding and retrieval-augmented generation. They are generally easier to learn and have moderate to low complexity.\n",
            "\n",
            "3. **Multi-Agent Systems**: These involve multiple agents working collaboratively, either in a vertical structure with a lead agent or a horizontal structure with equal collaboration. They are effective for complex, collaborative problem-solving but may involve higher costs and latency.\n",
            "\n",
            "Each type of agent is suited to different use cases: autonomous agents excel in independent operations, tool-using agents are ideal for tasks requiring external data interaction, and multi-agent systems are best for collaborative and complex tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final comparison: Basic vs Advanced RAG\n",
        "print(\"🚀 Advanced RAG Techniques Assignment - Final Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test queries for comparison\n",
        "test_queries = [\n",
        "    \"What are the key capabilities of AI agents?\",\n",
        "    \"How do you evaluate agent performance metrics?\",\n",
        "    \"Explain the benefits and challenges of multimodal AI systems\"\n",
        "]\n",
        "\n",
        "# Check if all components were created\n",
        "components_status = {\n",
        "    \"Basic Index\": index is not None,\n",
        "    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n",
        "    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n",
        "    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n",
        "    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n",
        "}\n",
        "\n",
        "print(\"\\n📊 Component Status:\")\n",
        "for component, status in components_status.items():\n",
        "    status_icon = \"✅\" if status else \"❌\"\n",
        "    print(f\"   {status_icon} {component}\")\n",
        "\n",
        "# Create basic query engine for comparison\n",
        "if index:\n",
        "    print(\"\\n🔍 Creating basic query engine for comparison...\")\n",
        "    basic_engine = index.as_query_engine(similarity_top_k=5)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"🆚 COMPARISON: Basic vs Advanced RAG\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\n📋 Test Query {i}: '{query}'\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Basic RAG\n",
        "        print(\"🔹 Basic RAG:\")\n",
        "        if basic_engine:\n",
        "            # Uncomment when testing:\n",
        "            # basic_response = basic_engine.query(query)\n",
        "            # print(f\"   Response: {str(basic_response)[:200]}...\")\n",
        "            print(\"   (Standard vector search + simple response)\")\n",
        "\n",
        "        # Advanced RAG (if implemented)\n",
        "        print(\"\\n🔸 Advanced RAG:\")\n",
        "        if components_status[\"Advanced Pipeline\"]:\n",
        "            # Uncomment when testing:\n",
        "            # advanced_response = advanced_pipeline.query(query)\n",
        "            # print(f\"   Response: {advanced_response}\")\n",
        "            print(\"   (Filtered + TreeSummarize + Structured output)\")\n",
        "        else:\n",
        "            print(\"   Complete the advanced pipeline function to test\")\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🎯 Assignment Status:\")\n",
        "completed_count = sum(components_status.values())\n",
        "total_count = len(components_status)\n",
        "\n",
        "print(f\"   Completed: {completed_count}/{total_count} components\")\n",
        "\n",
        "if completed_count == total_count:\n",
        "    print(\"\\n🎉 Congratulations! You've mastered Advanced RAG Techniques!\")\n",
        "    print(\"   ✅ Node postprocessors for result filtering\")\n",
        "    print(\"   ✅ Response synthesizers for better answers\")\n",
        "    print(\"   ✅ Structured outputs for reliable data\")\n",
        "    print(\"   ✅ Advanced pipelines combining all techniques\")\n",
        "    print(\"\\n🚀 You're ready for production RAG systems!\")\n",
        "else:\n",
        "    missing = total_count - completed_count\n",
        "    print(f\"\\n📝 Complete {missing} more components to finish the assignment:\")\n",
        "    for component, status in components_status.items():\n",
        "        if not status:\n",
        "            print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\n💡 Key learnings:\")\n",
        "print(\"   - Postprocessors improve result relevance and precision\")\n",
        "print(\"   - Different synthesizers work better for different query types\")\n",
        "print(\"   - Structured outputs enable reliable system integration\")\n",
        "print(\"   - Advanced techniques can be combined for production systems\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT0YDhyV_aIS",
        "outputId": "5053a095-7ba3-40ad-e471-9c3c60611775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Advanced RAG Techniques Assignment - Final Test\n",
            "============================================================\n",
            "\n",
            "📊 Component Status:\n",
            "   ✅ Basic Index\n",
            "   ✅ Similarity Filter\n",
            "   ✅ TreeSummarize\n",
            "   ✅ Structured Output\n",
            "   ✅ Advanced Pipeline\n",
            "\n",
            "🔍 Creating basic query engine for comparison...\n",
            "\n",
            "============================================================\n",
            "🆚 COMPARISON: Basic vs Advanced RAG\n",
            "============================================================\n",
            "\n",
            "📋 Test Query 1: 'What are the key capabilities of AI agents?'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "📋 Test Query 2: 'How do you evaluate agent performance metrics?'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "📋 Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "============================================================\n",
            "🎯 Assignment Status:\n",
            "   Completed: 5/5 components\n",
            "\n",
            "🎉 Congratulations! You've mastered Advanced RAG Techniques!\n",
            "   ✅ Node postprocessors for result filtering\n",
            "   ✅ Response synthesizers for better answers\n",
            "   ✅ Structured outputs for reliable data\n",
            "   ✅ Advanced pipelines combining all techniques\n",
            "\n",
            "🚀 You're ready for production RAG systems!\n",
            "\n",
            "💡 Key learnings:\n",
            "   - Postprocessors improve result relevance and precision\n",
            "   - Different synthesizers work better for different query types\n",
            "   - Structured outputs enable reliable system integration\n",
            "   - Advanced techniques can be combined for production systems\n"
          ]
        }
      ]
    }
  ]
}